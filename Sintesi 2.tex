\documentclass[a4paper]{article}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amssymb}
\usepackage[fleqn]{amsmath}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage[margin=1.6in]{geometry}

\begin{document}

\section*{Premessa e problemi incontrati}
In questi giorni abbiamo cercato di ricavare una rete Bayesiana dai dati forniti dalla prof. Mazuran. Ricordiamo che i dati sono costituiti da 6 file relativi ai 6 device che avevano generato più eventi in assoluto. Ogni file è suddiviso in 4 priorità, all'interno delle quali sono presenti due gruppi. Il primo gruppo \textit{''Distinct devices after 5 minutes''} presenta una lista di device per ciascuno degli eventi generati dal device del file. Il secondo invece contiene risultato del mining di itemset frequenti. \\
Inizialmente ci siamo concentrati sul secondo gruppo e abbiamo cercato di sfruttare il lavoro fatto sugli itemset frequenti per estrarre le correlazioni tra i device. Ci siamo però resi conto che è difficile lavorare unicamente su questi dati in quanto nella fase di training non è possibile considerare correttamente il peso di ciascun itemset (ovvero il supporto) e le sovrapposizioni tra itemset (poiché, ad esempio, l'uno potrebbe contenere l'altro). Anche considerare solo i device negli itemset frequenti e generare i dati per il training con il primo gruppo si è rivelato inefficace perché i ''frequent devices'' di un file non sono mai gli stessi che appaiono negli altri file (di fatto potrebbero essere considerati 6 problemi separati). In definitiva, correlazioni tra dati negli itemset frequenti sarebbero più immediati da scovare con una tecnica di data mining come le association rules, pertanto ci siamo concentrati unicamente sul primo gruppo di dati. \\
Per quanto riguardare il software, abbiamo riscontrato dei problemi con le una delle librerie principali per modelli grafici (Pgmpy \url{http://pgmpy.org/}. Gli \textit{score-based methods} di Pgmpy generano una struttura alla quale vengono poi associate distribuzioni di probabilità condizionale completamente uniforme (tutti i valori sono 0.5, oppure 0.25, ...), indipendentemente dal numero di variabili o dati utilizzati. Supponiamo sia un bug, anche perché siamo giunti a questo stesso risultato scrivendo indipendentemente due codici. \\
La seconda libreria, Libpgm (\url{http://pythonhosted.org/libpgm/}) ha a disposizione i \textit{constraint-based methods} che forniscono delle probabilità più sensate, ma in compenso non sempre genera un grafo aciclico per le variabili scelte (il che si traduce in un errore). Stiamo ancora cercando di capire se possiamo risolvere questi errori con delle modifiche alle librerie.


\section*{Scelta delle variabili}
Come anticipato, abbiamo considerato solo i device che compaiono più volte nel gruppo "Distinct devices after 5 minutes", provando con un numero  di variabili intorno a 10 per avere risultati in tempi rapidi. I seguenti sono i casi principali per la scelta della variabili da usare nella bayesian network:

\subsubsection*{Le 6 variabili associate ai device dei 6 file}
Queste variabili compaiono raramente al di fuori del proprio file e pertanto è difficile individuare correlazioni tra di esse.

\subsubsection*{Le n delle variabili con più occorrenze in assoluto o in relativo}
Scegliendo le n variabili con più occorrenze in assoluto si rischia di avere un bias verso i file con più record. Scegliere le variabili in funzione della frequenza con la quale appaiono nei file elimina questo problema, ma potrebbe introdurre l'errore opposto, ovvero selezionare variabili globalmente hanno una rilevanza minore.

\subsubsection*{L'aggiunta di 6 variabili ''trigger''}
Queste variabili verrebbero utilizzate per rappresentare il device del file che ha generato l'evento, servendo quindi da cause.

\subsubsection*{Aggiunta di una variabile ''priorità''}
Questa variabile è utile per distinguere tra i quattro livelli d'allarme, dato che le correlazioni individuate in un certo livello potrebbero non essere presenti in tutti gli altri. Purtroppo, non sempre la rete imparata sembrava considerarla nel modo corretto. La variabile nella rete bayesiana risultante dal processo di learning risultava infatti condizionata da alcuni nodi relativi alla presenza dei device, quando in realtà ci si attendeva il contrario.



\section*{Creazione del dataset}
Abbiamo generato un'istanza di training per ciascuna delle liste di device nel primo gruppo. Per i valori assegnati alle variabili abbiamo usato 1 quando la variabile era presente nella lista, 0 altrimenti. Anche inserendo le 6 variabili trigger che rappresentano il device del file che ha generato l'evento, rimanevano molti dati con un unico valore posto a 1, perchè alcuni device sono frequenti in un file, ma assenti in altri. Abbiamo eliminato i dati con un unico valore posto a 1, ma i problemi con le CPD uniformi ritornate da pgmpy sono rimasti.



-------------------------------------------- appunti e robe da inserire-----------

Abbiamo generato un'istanza di training per ciascuna delle liste di device nel primo gruppo. Per i valori assegnati alle variabili abbiamo usato 1 quando la variabile era presente nella lista, 0 altrimenti. Abbiamo provato a considerare la priorità come una variabile con valori [L0, L1, L2, L3] ma non sempre la rete imparata sembrava considerarla nel modo corretto (MOSTRA IMMAGINE e spiega in didascalia?), se non forzando i collegamenti prima del learning.

La variabile priorità nella rete bayesiana risultante dal processo di learning risultava condizionata da alcuni nodi relativi alla presenza dei device, quando in realtà ci si attendeva il contrario.

ABBIAMO considerato solo i device che compaiono più volte nel gruppo "Distinct devices after 5 minutes", provando con un numero
di variabili intorno a 10 per avere risultati in tempi rapidi. 

Considerare il numero occorrenze in assoluto nei 6 file per selezionare i device porta ad ottenere gli stessi device che si otterrebbero considerando il solo file EMC0019.txt, che ha ben 613 record associati includendo tutti i valori di priorità.
EHS60BE.txt ha solamente 132 record associati, mentre ES115H.txt pur avendo 268 record ha poche correlazioni frequenti. 
Infatti per ogni livello di priorità l'unico itemset frequente trovato con supporto maggiore di 0.5 è l' 1-itemset contenente il solo device
ES115H.txt. Quindi selezionando i 10 device più frequenti non compaiono molti dei 6 device che danno i nomi ai rispettivi file e
si trovano molti record che presentano solo 0 per ogni device considerato. 


Abbiamo poi pensato che sarebbe più utile avere i valori di priorità anche dei device nella sezione "Distinct devices after 5 minutes"
al posto dei livelli L0, L1, L2 e L3 associati ai soli 6 device. L0 inoltre ha molti pochi record associati.(aggiungi qualcosa su LIVELLI DI PRIORITA' INDIPENDENTI e INUTILI se vuoi)





Altre cose da dire:
- alcune priorità inutili e addirittura alcuni livelli di priorità potrebbero essere considerati indipendentemente dagli altri
- mostrare qualche rete e qualche cpd
- abbiamo provato ad escludere i dati con un unico valore posto a 1


\end{document}